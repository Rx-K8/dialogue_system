{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9957378795950986,
  "eval_steps": 500,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.4778430163860321,
      "learning_rate": 1.1086474501108649e-05,
      "loss": 3.3163,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4703878164291382,
      "learning_rate": 2.2172949002217298e-05,
      "loss": 4.1522,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7030219435691833,
      "learning_rate": 3.325942350332594e-05,
      "loss": 3.1592,
      "step": 75
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4450911283493042,
      "learning_rate": 4.4345898004434597e-05,
      "loss": 3.0151,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3755827844142914,
      "learning_rate": 5.543237250554324e-05,
      "loss": 2.7434,
      "step": 125
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.957922637462616,
      "learning_rate": 6.651884700665188e-05,
      "loss": 2.2967,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4609001874923706,
      "learning_rate": 7.760532150776053e-05,
      "loss": 2.5269,
      "step": 175
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3222547769546509,
      "learning_rate": 8.869179600886919e-05,
      "loss": 1.9191,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4314693510532379,
      "learning_rate": 9.977827050997783e-05,
      "loss": 2.479,
      "step": 225
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8664590120315552,
      "learning_rate": 0.00011086474501108647,
      "loss": 1.8894,
      "step": 250
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5337198972702026,
      "learning_rate": 0.00012195121951219512,
      "loss": 2.4603,
      "step": 275
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6569951176643372,
      "learning_rate": 0.00013303769401330377,
      "loss": 1.9039,
      "step": 300
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4230583906173706,
      "learning_rate": 0.00014412416851441242,
      "loss": 2.3305,
      "step": 325
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0301326513290405,
      "learning_rate": 0.00015521064301552106,
      "loss": 1.8235,
      "step": 350
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.38732966780662537,
      "learning_rate": 0.00016629711751662974,
      "loss": 2.4807,
      "step": 375
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9596758484840393,
      "learning_rate": 0.00017738359201773839,
      "loss": 1.8411,
      "step": 400
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.37563177943229675,
      "learning_rate": 0.00018847006651884703,
      "loss": 2.4407,
      "step": 425
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8842583894729614,
      "learning_rate": 0.00019955654101995565,
      "loss": 1.7978,
      "step": 450
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36334913969039917,
      "learning_rate": 0.00019999866010648437,
      "loss": 2.3877,
      "step": 475
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3432413339614868,
      "learning_rate": 0.00019999441482366592,
      "loss": 1.8379,
      "step": 500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3300069272518158,
      "learning_rate": 0.00019998726194877785,
      "loss": 2.4084,
      "step": 525
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.893515944480896,
      "learning_rate": 0.0001999772016898082,
      "loss": 1.7316,
      "step": 550
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3189506232738495,
      "learning_rate": 0.0001999642343392846,
      "loss": 2.3979,
      "step": 575
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6947365999221802,
      "learning_rate": 0.00019994836027426575,
      "loss": 1.8047,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.31974485516548157,
      "learning_rate": 0.0001999295799563305,
      "loss": 2.3425,
      "step": 625
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7089203000068665,
      "learning_rate": 0.00019990789393156436,
      "loss": 1.7248,
      "step": 650
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3422705829143524,
      "learning_rate": 0.00019988330283054372,
      "loss": 2.3633,
      "step": 675
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5793986320495605,
      "learning_rate": 0.00019985580736831741,
      "loss": 1.7614,
      "step": 700
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3400622606277466,
      "learning_rate": 0.00019982540834438597,
      "loss": 2.3582,
      "step": 725
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7278656363487244,
      "learning_rate": 0.00019979210664267834,
      "loss": 1.7708,
      "step": 750
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3663824200630188,
      "learning_rate": 0.00019975590323152628,
      "loss": 2.3014,
      "step": 775
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7937981486320496,
      "learning_rate": 0.00019971679916363607,
      "loss": 1.7145,
      "step": 800
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3878198564052582,
      "learning_rate": 0.00019967479557605805,
      "loss": 2.3343,
      "step": 825
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6633719205856323,
      "learning_rate": 0.00019962989369015334,
      "loss": 1.7539,
      "step": 850
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.339018851518631,
      "learning_rate": 0.00019958209481155858,
      "loss": 2.317,
      "step": 875
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7665901780128479,
      "learning_rate": 0.0001995314003301478,
      "loss": 1.7188,
      "step": 900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.37527528405189514,
      "learning_rate": 0.00019947781171999202,
      "loss": 2.2768,
      "step": 925
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5924409031867981,
      "learning_rate": 0.00019942133053931649,
      "loss": 1.685,
      "step": 950
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.37494614720344543,
      "learning_rate": 0.00019936195843045523,
      "loss": 2.3728,
      "step": 975
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6416605710983276,
      "learning_rate": 0.0001992996971198034,
      "loss": 1.7638,
      "step": 1000
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.40415555238723755,
      "learning_rate": 0.00019923454841776707,
      "loss": 2.3534,
      "step": 1025
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9079999923706055,
      "learning_rate": 0.00019916651421871052,
      "loss": 1.6605,
      "step": 1050
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3407445549964905,
      "learning_rate": 0.00019909559650090124,
      "loss": 2.3721,
      "step": 1075
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7294257283210754,
      "learning_rate": 0.00019902179732645228,
      "loss": 1.7923,
      "step": 1100
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40171539783477783,
      "learning_rate": 0.0001989451188412625,
      "loss": 2.3548,
      "step": 1125
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8007768392562866,
      "learning_rate": 0.00019886556327495394,
      "loss": 1.7127,
      "step": 1150
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.39387714862823486,
      "learning_rate": 0.00019878313294080714,
      "loss": 2.3485,
      "step": 1175
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7879685759544373,
      "learning_rate": 0.00019869783023569387,
      "loss": 1.7513,
      "step": 1200
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3144938349723816,
      "learning_rate": 0.00019860965764000735,
      "loss": 2.3812,
      "step": 1225
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6805601119995117,
      "learning_rate": 0.00019851861771759012,
      "loss": 1.6816,
      "step": 1250
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3513716459274292,
      "learning_rate": 0.00019842471311565962,
      "loss": 2.3618,
      "step": 1275
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8268184065818787,
      "learning_rate": 0.00019832794656473115,
      "loss": 1.7072,
      "step": 1300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.35154038667678833,
      "learning_rate": 0.00019822832087853837,
      "loss": 2.287,
      "step": 1325
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7204319834709167,
      "learning_rate": 0.00019812583895395167,
      "loss": 1.6459,
      "step": 1350
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.2956184148788452,
      "learning_rate": 0.00019802050377089377,
      "loss": 2.2024,
      "step": 1375
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7152166366577148,
      "learning_rate": 0.00019791231839225314,
      "loss": 1.6647,
      "step": 1400
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.334876149892807,
      "learning_rate": 0.00019780128596379504,
      "loss": 2.3362,
      "step": 1425
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8960980772972107,
      "learning_rate": 0.00019768740971406982,
      "loss": 1.6483,
      "step": 1450
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.33561626076698303,
      "learning_rate": 0.00019757069295431922,
      "loss": 2.3331,
      "step": 1475
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5796000361442566,
      "learning_rate": 0.0001974511390783801,
      "loss": 1.7809,
      "step": 1500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3395475447177887,
      "learning_rate": 0.00019732875156258555,
      "loss": 2.3065,
      "step": 1525
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6551699638366699,
      "learning_rate": 0.0001972035339656641,
      "loss": 1.7464,
      "step": 1550
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.365226686000824,
      "learning_rate": 0.00019707548992863605,
      "loss": 2.3567,
      "step": 1575
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0061050653457642,
      "learning_rate": 0.0001969446231747075,
      "loss": 1.5668,
      "step": 1600
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.303180068731308,
      "learning_rate": 0.00019681093750916246,
      "loss": 2.3278,
      "step": 1625
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8459476232528687,
      "learning_rate": 0.00019667443681925178,
      "loss": 1.6813,
      "step": 1650
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3673023581504822,
      "learning_rate": 0.0001965351250740804,
      "loss": 2.2767,
      "step": 1675
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9649462103843689,
      "learning_rate": 0.00019639300632449182,
      "loss": 1.7516,
      "step": 1700
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3077375888824463,
      "learning_rate": 0.00019624808470295032,
      "loss": 2.2997,
      "step": 1725
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6146436929702759,
      "learning_rate": 0.00019610036442342085,
      "loss": 1.6893,
      "step": 1750
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.31582731008529663,
      "learning_rate": 0.00019594984978124646,
      "loss": 2.3479,
      "step": 1775
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7676447629928589,
      "learning_rate": 0.0001957965451530234,
      "loss": 1.607,
      "step": 1800
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3544039726257324,
      "learning_rate": 0.00019564045499647378,
      "loss": 2.2805,
      "step": 1825
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5931374430656433,
      "learning_rate": 0.0001954815838503162,
      "loss": 1.6429,
      "step": 1850
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.375205934047699,
      "learning_rate": 0.00019531993633413342,
      "loss": 2.2517,
      "step": 1875
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.829899251461029,
      "learning_rate": 0.0001951555171482384,
      "loss": 1.7446,
      "step": 1900
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3082304894924164,
      "learning_rate": 0.00019498833107353737,
      "loss": 2.3239,
      "step": 1925
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8571102619171143,
      "learning_rate": 0.00019481838297139085,
      "loss": 1.7881,
      "step": 1950
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3960763216018677,
      "learning_rate": 0.00019464567778347243,
      "loss": 2.2813,
      "step": 1975
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8066320419311523,
      "learning_rate": 0.0001944702205316249,
      "loss": 1.6143,
      "step": 2000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3968886137008667,
      "learning_rate": 0.00019429201631771434,
      "loss": 2.3549,
      "step": 2025
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5523771643638611,
      "learning_rate": 0.0001941110703234818,
      "loss": 1.7118,
      "step": 2050
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.39371761679649353,
      "learning_rate": 0.00019392738781039248,
      "loss": 2.1201,
      "step": 2075
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6576877236366272,
      "learning_rate": 0.00019374097411948288,
      "loss": 1.6014,
      "step": 2100
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.36177971959114075,
      "learning_rate": 0.00019355183467120547,
      "loss": 2.2969,
      "step": 2125
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9238567352294922,
      "learning_rate": 0.00019336770151273243,
      "loss": 1.6562,
      "step": 2150
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3602190315723419,
      "learning_rate": 0.0001931732356070001,
      "loss": 2.308,
      "step": 2175
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8286628127098083,
      "learning_rate": 0.00019297606045234192,
      "loss": 1.6845,
      "step": 2200
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.31562623381614685,
      "learning_rate": 0.00019277618178212725,
      "loss": 2.3488,
      "step": 2225
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7163578271865845,
      "learning_rate": 0.0001925736054083371,
      "loss": 1.5246,
      "step": 2250
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3818890154361725,
      "learning_rate": 0.000192368337221395,
      "loss": 2.2465,
      "step": 2275
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7358493804931641,
      "learning_rate": 0.0001921603831899959,
      "loss": 1.6674,
      "step": 2300
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3330335319042206,
      "learning_rate": 0.00019194974936093237,
      "loss": 2.2576,
      "step": 2325
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6354450583457947,
      "learning_rate": 0.00019173644185891905,
      "loss": 1.6834,
      "step": 2350
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.304910808801651,
      "learning_rate": 0.00019152046688641433,
      "loss": 2.3985,
      "step": 2375
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5404509902000427,
      "learning_rate": 0.00019131062718532094,
      "loss": 1.7249,
      "step": 2400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3667105436325073,
      "learning_rate": 0.0001910894422595717,
      "loss": 2.2305,
      "step": 2425
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6925656199455261,
      "learning_rate": 0.0001908656086764909,
      "loss": 1.6335,
      "step": 2450
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.32470011711120605,
      "learning_rate": 0.00019063913294460952,
      "loss": 2.2816,
      "step": 2475
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8653776049613953,
      "learning_rate": 0.0001904100216492858,
      "loss": 1.6538,
      "step": 2500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.32102248072624207,
      "learning_rate": 0.00019017828145251371,
      "loss": 2.2419,
      "step": 2525
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.596332848072052,
      "learning_rate": 0.00018994391909272915,
      "loss": 1.584,
      "step": 2550
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.31523391604423523,
      "learning_rate": 0.0001897069413846141,
      "loss": 2.3366,
      "step": 2575
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6910350918769836,
      "learning_rate": 0.00018946735521889848,
      "loss": 1.6329,
      "step": 2600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3479898273944855,
      "learning_rate": 0.0001892251675621598,
      "loss": 2.3169,
      "step": 2625
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6297775506973267,
      "learning_rate": 0.0001889803854566204,
      "loss": 1.7118,
      "step": 2650
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.32056060433387756,
      "learning_rate": 0.00018873301601994295,
      "loss": 2.1749,
      "step": 2675
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7595468163490295,
      "learning_rate": 0.0001884830664450233,
      "loss": 1.5841,
      "step": 2700
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3161297142505646,
      "learning_rate": 0.00018823054399978134,
      "loss": 2.2795,
      "step": 2725
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.747500479221344,
      "learning_rate": 0.00018797545602694987,
      "loss": 1.5997,
      "step": 2750
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3775307238101959,
      "learning_rate": 0.0001877178099438608,
      "loss": 2.2186,
      "step": 2775
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7460368871688843,
      "learning_rate": 0.00018745761324222954,
      "loss": 1.6944,
      "step": 2800
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.36816760897636414,
      "learning_rate": 0.00018719487348793743,
      "loss": 2.2122,
      "step": 2825
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6883447170257568,
      "learning_rate": 0.0001869295983208114,
      "loss": 1.5896,
      "step": 2850
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.300542414188385,
      "learning_rate": 0.00018666179545440194,
      "loss": 2.3156,
      "step": 2875
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7016805410385132,
      "learning_rate": 0.0001863914726757589,
      "loss": 1.5687,
      "step": 2900
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3737039566040039,
      "learning_rate": 0.00018611863784520505,
      "loss": 2.3053,
      "step": 2925
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7617275714874268,
      "learning_rate": 0.00018584329889610726,
      "loss": 1.6224,
      "step": 2950
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.386533260345459,
      "learning_rate": 0.0001855654638346462,
      "loss": 2.2309,
      "step": 2975
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7526244521141052,
      "learning_rate": 0.00018528514073958328,
      "loss": 1.6547,
      "step": 3000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.35043102502822876,
      "learning_rate": 0.00018500233776202582,
      "loss": 2.2624,
      "step": 3025
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6014214158058167,
      "learning_rate": 0.0001847170631251901,
      "loss": 1.6154,
      "step": 3050
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.30745208263397217,
      "learning_rate": 0.00018442932512416205,
      "loss": 2.2808,
      "step": 3075
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5576789379119873,
      "learning_rate": 0.00018413913212565636,
      "loss": 1.6446,
      "step": 3100
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.35757172107696533,
      "learning_rate": 0.00018384649256777285,
      "loss": 2.2257,
      "step": 3125
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6462569236755371,
      "learning_rate": 0.00018355141495975143,
      "loss": 1.6982,
      "step": 3150
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4711827039718628,
      "learning_rate": 0.00018325390788172436,
      "loss": 2.2774,
      "step": 3175
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6675664186477661,
      "learning_rate": 0.00018295397998446705,
      "loss": 1.6152,
      "step": 3200
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4242156147956848,
      "learning_rate": 0.00018265163998914635,
      "loss": 2.3137,
      "step": 3225
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6965458989143372,
      "learning_rate": 0.00018234689668706697,
      "loss": 1.6462,
      "step": 3250
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.36307692527770996,
      "learning_rate": 0.00018203975893941595,
      "loss": 2.2745,
      "step": 3275
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6957436800003052,
      "learning_rate": 0.00018173023567700486,
      "loss": 1.5781,
      "step": 3300
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4210176467895508,
      "learning_rate": 0.0001814183359000102,
      "loss": 2.2604,
      "step": 3325
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5588366985321045,
      "learning_rate": 0.00018110406867771173,
      "loss": 1.5835,
      "step": 3350
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3163009583950043,
      "learning_rate": 0.0001807874431482286,
      "loss": 2.228,
      "step": 3375
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7356525659561157,
      "learning_rate": 0.00018046846851825382,
      "loss": 1.5815,
      "step": 3400
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.36065131425857544,
      "learning_rate": 0.0001801471540627865,
      "loss": 2.2746,
      "step": 3425
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6758153438568115,
      "learning_rate": 0.00017982350912486205,
      "loss": 1.5408,
      "step": 3450
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3720538020133972,
      "learning_rate": 0.00017949754311528065,
      "loss": 2.3177,
      "step": 3475
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6570168733596802,
      "learning_rate": 0.00017916926551233355,
      "loss": 1.6987,
      "step": 3500
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3767651915550232,
      "learning_rate": 0.00017883868586152736,
      "loss": 2.2887,
      "step": 3525
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6068530678749084,
      "learning_rate": 0.00017850581377530674,
      "loss": 1.6443,
      "step": 3550
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3967759907245636,
      "learning_rate": 0.0001781706589327746,
      "loss": 2.2781,
      "step": 3575
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6653191447257996,
      "learning_rate": 0.0001778332310794109,
      "loss": 1.6377,
      "step": 3600
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.33475711941719055,
      "learning_rate": 0.00017749354002678916,
      "loss": 2.2992,
      "step": 3625
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5724251866340637,
      "learning_rate": 0.0001771515956522911,
      "loss": 1.6761,
      "step": 3650
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.33576276898384094,
      "learning_rate": 0.0001768074078988196,
      "loss": 2.2657,
      "step": 3675
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.8384671211242676,
      "learning_rate": 0.00017646098677450944,
      "loss": 1.6258,
      "step": 3700
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.31725043058395386,
      "learning_rate": 0.00017611234235243638,
      "loss": 2.2148,
      "step": 3725
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6958647966384888,
      "learning_rate": 0.0001757614847703242,
      "loss": 1.7005,
      "step": 3750
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3158700466156006,
      "learning_rate": 0.0001754084242302499,
      "loss": 2.2159,
      "step": 3775
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.647495687007904,
      "learning_rate": 0.00017505317099834715,
      "loss": 1.6668,
      "step": 3800
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.37749621272087097,
      "learning_rate": 0.0001746957354045077,
      "loss": 2.1688,
      "step": 3825
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.628527820110321,
      "learning_rate": 0.000174336127842081,
      "loss": 1.6887,
      "step": 3850
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.3248734176158905,
      "learning_rate": 0.00017397435876757205,
      "loss": 2.1333,
      "step": 3875
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5565138459205627,
      "learning_rate": 0.00017361043870033725,
      "loss": 1.7097,
      "step": 3900
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.3169674873352051,
      "learning_rate": 0.00017324437822227872,
      "loss": 2.0752,
      "step": 3925
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6420366764068604,
      "learning_rate": 0.00017287618797753624,
      "loss": 1.6688,
      "step": 3950
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.34812986850738525,
      "learning_rate": 0.00017250587867217827,
      "loss": 2.1202,
      "step": 3975
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6148785948753357,
      "learning_rate": 0.00017213346107389015,
      "loss": 1.714,
      "step": 4000
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.4008443355560303,
      "learning_rate": 0.0001717589460116612,
      "loss": 2.0845,
      "step": 4025
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.673059344291687,
      "learning_rate": 0.00017138234437546993,
      "loss": 1.6978,
      "step": 4050
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.33934643864631653,
      "learning_rate": 0.00017100366711596732,
      "loss": 2.083,
      "step": 4075
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5796473026275635,
      "learning_rate": 0.00017062292524415825,
      "loss": 1.5999,
      "step": 4100
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.3796963393688202,
      "learning_rate": 0.0001702401298310815,
      "loss": 2.0357,
      "step": 4125
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8681184649467468,
      "learning_rate": 0.00016985529200748788,
      "loss": 1.7285,
      "step": 4150
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.46628233790397644,
      "learning_rate": 0.0001694684229635164,
      "loss": 2.0741,
      "step": 4175
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5329144597053528,
      "learning_rate": 0.000169079533948369,
      "loss": 1.6219,
      "step": 4200
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.42752569913864136,
      "learning_rate": 0.0001686886362699834,
      "loss": 2.0867,
      "step": 4225
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6449394226074219,
      "learning_rate": 0.00016829574129470433,
      "loss": 1.5734,
      "step": 4250
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.39669474959373474,
      "learning_rate": 0.000167900860446953,
      "loss": 2.151,
      "step": 4275
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5729373097419739,
      "learning_rate": 0.0001675040052088949,
      "loss": 1.6909,
      "step": 4300
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.40476998686790466,
      "learning_rate": 0.00016710518712010602,
      "loss": 2.0386,
      "step": 4325
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6821460723876953,
      "learning_rate": 0.00016670441777723714,
      "loss": 1.6833,
      "step": 4350
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.3915916383266449,
      "learning_rate": 0.00016630170883367678,
      "loss": 2.1056,
      "step": 4375
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.8011823296546936,
      "learning_rate": 0.00016589707199921223,
      "loss": 1.639,
      "step": 4400
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.4110146462917328,
      "learning_rate": 0.00016549051903968915,
      "loss": 2.1093,
      "step": 4425
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.8153634667396545,
      "learning_rate": 0.00016508206177666938,
      "loss": 1.7911,
      "step": 4450
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.4663480818271637,
      "learning_rate": 0.00016467171208708732,
      "loss": 2.1371,
      "step": 4475
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5957381725311279,
      "learning_rate": 0.00016425948190290442,
      "loss": 1.6098,
      "step": 4500
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.4251733422279358,
      "learning_rate": 0.0001638453832107622,
      "loss": 2.0644,
      "step": 4525
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.677977442741394,
      "learning_rate": 0.00016344610175062153,
      "loss": 1.652,
      "step": 4550
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.354713499546051,
      "learning_rate": 0.00016302837576144628,
      "loss": 2.1196,
      "step": 4575
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7339861392974854,
      "learning_rate": 0.00016260881706185566,
      "loss": 1.6565,
      "step": 4600
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.3771268129348755,
      "learning_rate": 0.00016218743785158656,
      "loss": 2.0886,
      "step": 4625
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7199158072471619,
      "learning_rate": 0.00016176425038331177,
      "loss": 1.6723,
      "step": 4650
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.35058125853538513,
      "learning_rate": 0.00016133926696228388,
      "loss": 2.1756,
      "step": 4675
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6861050128936768,
      "learning_rate": 0.00016091249994597723,
      "loss": 1.7016,
      "step": 4700
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.3797329366207123,
      "learning_rate": 0.00016048396174372893,
      "loss": 2.1096,
      "step": 4725
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6198300719261169,
      "learning_rate": 0.00016005366481637766,
      "loss": 1.6424,
      "step": 4750
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.3659067153930664,
      "learning_rate": 0.00015962162167590158,
      "loss": 2.1093,
      "step": 4775
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7470684051513672,
      "learning_rate": 0.00015918784488505445,
      "loss": 1.6647,
      "step": 4800
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.413787305355072,
      "learning_rate": 0.0001587523470570003,
      "loss": 2.1435,
      "step": 4825
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.710624635219574,
      "learning_rate": 0.0001583151408549467,
      "loss": 1.749,
      "step": 4850
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.3561914265155792,
      "learning_rate": 0.00015787623899177655,
      "loss": 2.0659,
      "step": 4875
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.668977677822113,
      "learning_rate": 0.0001574356542296784,
      "loss": 1.7064,
      "step": 4900
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.3688157796859741,
      "learning_rate": 0.00015699339937977536,
      "loss": 2.0631,
      "step": 4925
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6712630391120911,
      "learning_rate": 0.00015654948730175268,
      "loss": 1.65,
      "step": 4950
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.3817174434661865,
      "learning_rate": 0.0001561039309034836,
      "loss": 2.171,
      "step": 4975
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5923586487770081,
      "learning_rate": 0.0001556567431406542,
      "loss": 1.6422,
      "step": 5000
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.3843621611595154,
      "learning_rate": 0.00015520793701638674,
      "loss": 2.0655,
      "step": 5025
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7903796434402466,
      "learning_rate": 0.0001547575255808613,
      "loss": 1.7002,
      "step": 5050
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.37284135818481445,
      "learning_rate": 0.00015430552193093657,
      "loss": 2.127,
      "step": 5075
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7009207606315613,
      "learning_rate": 0.0001538519392097689,
      "loss": 1.6189,
      "step": 5100
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.4304085373878479,
      "learning_rate": 0.00015339679060643016,
      "loss": 2.1423,
      "step": 5125
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.625126302242279,
      "learning_rate": 0.00015294008935552418,
      "loss": 1.7355,
      "step": 5150
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.42847153544425964,
      "learning_rate": 0.00015248184873680205,
      "loss": 2.131,
      "step": 5175
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6109024882316589,
      "learning_rate": 0.00015202208207477585,
      "loss": 1.7321,
      "step": 5200
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.3765791058540344,
      "learning_rate": 0.00015156080273833123,
      "loss": 2.0777,
      "step": 5225
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5046596527099609,
      "learning_rate": 0.00015109802414033877,
      "loss": 1.6207,
      "step": 5250
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.41161927580833435,
      "learning_rate": 0.00015063375973726388,
      "loss": 2.0561,
      "step": 5275
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7669521570205688,
      "learning_rate": 0.00015016802302877542,
      "loss": 1.7129,
      "step": 5300
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.3992725908756256,
      "learning_rate": 0.0001497008275573534,
      "loss": 2.1533,
      "step": 5325
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6287111043930054,
      "learning_rate": 0.00014923218690789507,
      "loss": 1.6681,
      "step": 5350
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.35947251319885254,
      "learning_rate": 0.00014876211470731982,
      "loss": 2.1011,
      "step": 5375
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6195052266120911,
      "learning_rate": 0.00014829062462417314,
      "loss": 1.6565,
      "step": 5400
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.444501131772995,
      "learning_rate": 0.00014781773036822902,
      "loss": 2.1133,
      "step": 5425
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6405837535858154,
      "learning_rate": 0.00014734344569009125,
      "loss": 1.6211,
      "step": 5450
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.4144488573074341,
      "learning_rate": 0.00014686778438079384,
      "loss": 2.1196,
      "step": 5475
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7064637541770935,
      "learning_rate": 0.00014639076027139983,
      "loss": 1.6337,
      "step": 5500
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.4486200511455536,
      "learning_rate": 0.00014591238723259898,
      "loss": 2.0984,
      "step": 5525
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6199636459350586,
      "learning_rate": 0.00014543267917430482,
      "loss": 1.6979,
      "step": 5550
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.4207436144351959,
      "learning_rate": 0.00014495165004524982,
      "loss": 2.1402,
      "step": 5575
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7539130449295044,
      "learning_rate": 0.00014446931383258003,
      "loss": 1.612,
      "step": 5600
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.3852086067199707,
      "learning_rate": 0.00014398568456144823,
      "loss": 2.0963,
      "step": 5625
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6814830303192139,
      "learning_rate": 0.00014350077629460617,
      "loss": 1.6578,
      "step": 5650
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.3968985378742218,
      "learning_rate": 0.00014301460313199572,
      "loss": 2.0926,
      "step": 5675
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6384782195091248,
      "learning_rate": 0.00014252717921033867,
      "loss": 1.6823,
      "step": 5700
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.39636456966400146,
      "learning_rate": 0.00014203851870272602,
      "loss": 2.1306,
      "step": 5725
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6511243581771851,
      "learning_rate": 0.00014154863581820543,
      "loss": 1.7497,
      "step": 5750
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.3884822130203247,
      "learning_rate": 0.00014105754480136845,
      "loss": 2.0305,
      "step": 5775
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.7342461347579956,
      "learning_rate": 0.00014056525993193608,
      "loss": 1.7402,
      "step": 5800
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.4543343484401703,
      "learning_rate": 0.0001400717955243436,
      "loss": 2.0992,
      "step": 5825
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7135773301124573,
      "learning_rate": 0.00013957716592732445,
      "loss": 1.6516,
      "step": 5850
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.43912026286125183,
      "learning_rate": 0.0001390813855234928,
      "loss": 2.1323,
      "step": 5875
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7495757937431335,
      "learning_rate": 0.00013858446872892552,
      "loss": 1.6235,
      "step": 5900
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.4602263867855072,
      "learning_rate": 0.00013808642999274298,
      "loss": 2.0355,
      "step": 5925
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6093501448631287,
      "learning_rate": 0.00013758728379668878,
      "loss": 1.7642,
      "step": 5950
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.47785449028015137,
      "learning_rate": 0.0001370870446547088,
      "loss": 2.0714,
      "step": 5975
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6401072144508362,
      "learning_rate": 0.00013658572711252898,
      "loss": 1.6211,
      "step": 6000
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.41532930731773376,
      "learning_rate": 0.00013608334574723263,
      "loss": 2.1104,
      "step": 6025
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6601437330245972,
      "learning_rate": 0.00013557991516683637,
      "loss": 1.7278,
      "step": 6050
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.41797226667404175,
      "learning_rate": 0.0001350754500098654,
      "loss": 2.1059,
      "step": 6075
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6581728458404541,
      "learning_rate": 0.00013456996494492794,
      "loss": 1.6925,
      "step": 6100
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.42231252789497375,
      "learning_rate": 0.0001340634746702885,
      "loss": 2.0392,
      "step": 6125
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6158545017242432,
      "learning_rate": 0.00013355599391344074,
      "loss": 1.595,
      "step": 6150
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.4376813471317291,
      "learning_rate": 0.00013304753743067905,
      "loss": 2.031,
      "step": 6175
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6615711450576782,
      "learning_rate": 0.00013253812000666958,
      "loss": 1.6354,
      "step": 6200
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.40070709586143494,
      "learning_rate": 0.00013202775645402022,
      "loss": 2.0575,
      "step": 6225
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6720384955406189,
      "learning_rate": 0.00013151646161285,
      "loss": 1.6749,
      "step": 6250
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.3977760076522827,
      "learning_rate": 0.0001310042503503576,
      "loss": 2.1234,
      "step": 6275
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.5672470927238464,
      "learning_rate": 0.00013049113756038883,
      "loss": 1.6268,
      "step": 6300
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.42361220717430115,
      "learning_rate": 0.00012997713816300383,
      "loss": 1.9267,
      "step": 6325
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.665077805519104,
      "learning_rate": 0.00012946226710404307,
      "loss": 1.5859,
      "step": 6350
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.46871304512023926,
      "learning_rate": 0.00012894653935469278,
      "loss": 2.1699,
      "step": 6375
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6386265158653259,
      "learning_rate": 0.0001284299699110497,
      "loss": 1.6363,
      "step": 6400
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.3782769739627838,
      "learning_rate": 0.00012791257379368492,
      "loss": 2.0205,
      "step": 6425
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6670806407928467,
      "learning_rate": 0.00012739436604720713,
      "loss": 1.7438,
      "step": 6450
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.4001569151878357,
      "learning_rate": 0.00012687536173982533,
      "loss": 2.1027,
      "step": 6475
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7814855575561523,
      "learning_rate": 0.0001263555759629104,
      "loss": 1.6703,
      "step": 6500
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.45603957772254944,
      "learning_rate": 0.0001258350238305566,
      "loss": 2.0886,
      "step": 6525
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7742573618888855,
      "learning_rate": 0.0001253137204791418,
      "loss": 1.6675,
      "step": 6550
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.44949308037757874,
      "learning_rate": 0.00012479168106688753,
      "loss": 2.1304,
      "step": 6575
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5277451872825623,
      "learning_rate": 0.00012426892077341815,
      "loss": 1.7013,
      "step": 6600
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.4305582046508789,
      "learning_rate": 0.00012374545479931946,
      "loss": 2.0591,
      "step": 6625
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6271048188209534,
      "learning_rate": 0.00012322129836569675,
      "loss": 1.6391,
      "step": 6650
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.4596141278743744,
      "learning_rate": 0.00012269646671373216,
      "loss": 2.0349,
      "step": 6675
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.73940110206604,
      "learning_rate": 0.00012217097510424152,
      "loss": 1.6362,
      "step": 6700
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.38002610206604004,
      "learning_rate": 0.00012164483881723063,
      "loss": 2.0543,
      "step": 6725
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5933482646942139,
      "learning_rate": 0.0001211180731514509,
      "loss": 1.6116,
      "step": 6750
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.3799440860748291,
      "learning_rate": 0.00012059069342395451,
      "loss": 2.1452,
      "step": 6775
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6252946257591248,
      "learning_rate": 0.00012006271496964912,
      "loss": 1.6955,
      "step": 6800
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.46913275122642517,
      "learning_rate": 0.00011953415314085182,
      "loss": 2.0724,
      "step": 6825
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.8885011076927185,
      "learning_rate": 0.0001190050233068428,
      "loss": 1.4933,
      "step": 6850
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.4586133658885956,
      "learning_rate": 0.00011847534085341854,
      "loss": 2.0991,
      "step": 6875
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5758772492408752,
      "learning_rate": 0.00011794512118244423,
      "loss": 1.6494,
      "step": 6900
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.49051007628440857,
      "learning_rate": 0.0001174143797114061,
      "loss": 2.0562,
      "step": 6925
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.7173659205436707,
      "learning_rate": 0.00011688313187296297,
      "loss": 1.6042,
      "step": 6950
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.4789145588874817,
      "learning_rate": 0.00011635139311449767,
      "loss": 2.1559,
      "step": 6975
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.7587347030639648,
      "learning_rate": 0.00011581917889766769,
      "loss": 1.5418,
      "step": 7000
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.4529414176940918,
      "learning_rate": 0.00011528650469795578,
      "loss": 2.0765,
      "step": 7025
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7574065923690796,
      "learning_rate": 0.00011475338600421979,
      "loss": 1.7174,
      "step": 7050
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.34687960147857666,
      "learning_rate": 0.0001142198383182423,
      "loss": 2.1281,
      "step": 7075
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7459308505058289,
      "learning_rate": 0.00011368587715428011,
      "loss": 1.7293,
      "step": 7100
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.411106675863266,
      "learning_rate": 0.00011315151803861284,
      "loss": 2.0521,
      "step": 7125
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.8150457143783569,
      "learning_rate": 0.00011261677650909153,
      "loss": 1.6757,
      "step": 7150
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.41040971875190735,
      "learning_rate": 0.00011208166811468696,
      "loss": 2.1391,
      "step": 7175
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.7285361886024475,
      "learning_rate": 0.00011154620841503742,
      "loss": 1.571,
      "step": 7200
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.4266156554222107,
      "learning_rate": 0.0001110104129799962,
      "loss": 2.0673,
      "step": 7225
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.8110416531562805,
      "learning_rate": 0.00011047429738917909,
      "loss": 1.6514,
      "step": 7250
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5072996020317078,
      "learning_rate": 0.00010993787723151116,
      "loss": 2.0373,
      "step": 7275
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6731110215187073,
      "learning_rate": 0.0001094011681047735,
      "loss": 1.6572,
      "step": 7300
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3741081953048706,
      "learning_rate": 0.00010886418561514979,
      "loss": 2.0619,
      "step": 7325
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.7022399306297302,
      "learning_rate": 0.00010832694537677241,
      "loss": 1.7171,
      "step": 7350
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.45490580797195435,
      "learning_rate": 0.00010778946301126833,
      "loss": 2.089,
      "step": 7375
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6155588030815125,
      "learning_rate": 0.00010725175414730514,
      "loss": 1.6249,
      "step": 7400
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.4460187554359436,
      "learning_rate": 0.0001067138344201364,
      "loss": 2.0796,
      "step": 7425
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6160805225372314,
      "learning_rate": 0.000106175719471147,
      "loss": 1.5847,
      "step": 7450
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.44386187195777893,
      "learning_rate": 0.00010563742494739843,
      "loss": 2.038,
      "step": 7475
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5725963115692139,
      "learning_rate": 0.00010509896650117383,
      "loss": 1.6488,
      "step": 7500
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4323541522026062,
      "learning_rate": 0.0001045603597895227,
      "loss": 2.0201,
      "step": 7525
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.7549457550048828,
      "learning_rate": 0.00010402162047380581,
      "loss": 1.7436,
      "step": 7550
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3843177556991577,
      "learning_rate": 0.00010348276421923973,
      "loss": 1.9182,
      "step": 7575
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6758061051368713,
      "learning_rate": 0.00010294380669444127,
      "loss": 1.7621,
      "step": 7600
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.41886991262435913,
      "learning_rate": 0.000102404763570972,
      "loss": 1.8896,
      "step": 7625
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7297837138175964,
      "learning_rate": 0.00010186565052288244,
      "loss": 1.6366,
      "step": 7650
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.4033200442790985,
      "learning_rate": 0.0001013264832262563,
      "loss": 1.8947,
      "step": 7675
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.875472366809845,
      "learning_rate": 0.00010078727735875486,
      "loss": 1.8321,
      "step": 7700
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.41834914684295654,
      "learning_rate": 0.00010024804859916082,
      "loss": 1.9578,
      "step": 7725
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6556607484817505,
      "learning_rate": 9.970881262692251e-05,
      "loss": 1.7892,
      "step": 7750
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.407331258058548,
      "learning_rate": 9.916958512169807e-05,
      "loss": 1.9331,
      "step": 7775
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.662638783454895,
      "learning_rate": 9.86303817628994e-05,
      "loss": 1.6919,
      "step": 7800
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.396883100271225,
      "learning_rate": 9.80912182292363e-05,
      "loss": 1.89,
      "step": 7825
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.7299787402153015,
      "learning_rate": 9.755211019826047e-05,
      "loss": 1.73,
      "step": 7850
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.3884396553039551,
      "learning_rate": 9.701307334590993e-05,
      "loss": 1.9172,
      "step": 7875
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.702142059803009,
      "learning_rate": 9.647412334605269e-05,
      "loss": 1.6902,
      "step": 7900
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.4567689597606659,
      "learning_rate": 9.59352758700316e-05,
      "loss": 1.8423,
      "step": 7925
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7106747031211853,
      "learning_rate": 9.539654658620819e-05,
      "loss": 1.7482,
      "step": 7950
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.45436498522758484,
      "learning_rate": 9.485795115950733e-05,
      "loss": 1.9214,
      "step": 7975
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.709514856338501,
      "learning_rate": 9.431950525096161e-05,
      "loss": 1.679,
      "step": 8000
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.42592769861221313,
      "learning_rate": 9.378122451725605e-05,
      "loss": 1.9003,
      "step": 8025
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6844670176506042,
      "learning_rate": 9.324312461027274e-05,
      "loss": 1.6863,
      "step": 8050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.48044514656066895,
      "learning_rate": 9.270522117663579e-05,
      "loss": 1.9064,
      "step": 8075
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.8218473792076111,
      "learning_rate": 9.216752985725639e-05,
      "loss": 1.5772,
      "step": 8100
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.3811093270778656,
      "learning_rate": 9.163006628687788e-05,
      "loss": 1.882,
      "step": 8125
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.7463656067848206,
      "learning_rate": 9.109284609362129e-05,
      "loss": 1.6119,
      "step": 8150
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.37091800570487976,
      "learning_rate": 9.055588489853084e-05,
      "loss": 1.8803,
      "step": 8175
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.819525957107544,
      "learning_rate": 9.001919831511966e-05,
      "loss": 1.616,
      "step": 8200
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.4661475718021393,
      "learning_rate": 8.948280194891587e-05,
      "loss": 1.806,
      "step": 8225
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.8205118179321289,
      "learning_rate": 8.894671139700885e-05,
      "loss": 1.7327,
      "step": 8250
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.3654542863368988,
      "learning_rate": 8.841094224759556e-05,
      "loss": 1.8771,
      "step": 8275
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.7784925103187561,
      "learning_rate": 8.787551007952743e-05,
      "loss": 1.8039,
      "step": 8300
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.41223475337028503,
      "learning_rate": 8.734043046185727e-05,
      "loss": 1.8707,
      "step": 8325
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6579477190971375,
      "learning_rate": 8.680571895338662e-05,
      "loss": 1.7208,
      "step": 8350
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.3779403865337372,
      "learning_rate": 8.627139110221325e-05,
      "loss": 1.8916,
      "step": 8375
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6588732600212097,
      "learning_rate": 8.573746244527914e-05,
      "loss": 1.7273,
      "step": 8400
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3724834620952606,
      "learning_rate": 8.520394850791875e-05,
      "loss": 1.813,
      "step": 8425
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.7078732252120972,
      "learning_rate": 8.467086480340743e-05,
      "loss": 1.6646,
      "step": 8450
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.46432945132255554,
      "learning_rate": 8.413822683251043e-05,
      "loss": 1.8534,
      "step": 8475
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.7642360329627991,
      "learning_rate": 8.360605008303218e-05,
      "loss": 1.7753,
      "step": 8500
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.417015939950943,
      "learning_rate": 8.307435002936588e-05,
      "loss": 1.8713,
      "step": 8525
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.7198562622070312,
      "learning_rate": 8.25431421320437e-05,
      "loss": 1.6845,
      "step": 8550
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.40888822078704834,
      "learning_rate": 8.201244183728697e-05,
      "loss": 1.8713,
      "step": 8575
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6674720048904419,
      "learning_rate": 8.148226457655725e-05,
      "loss": 1.6582,
      "step": 8600
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.4583313763141632,
      "learning_rate": 8.095262576610761e-05,
      "loss": 1.9066,
      "step": 8625
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.8740103244781494,
      "learning_rate": 8.042354080653421e-05,
      "loss": 1.6979,
      "step": 8650
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5381428599357605,
      "learning_rate": 7.989502508232864e-05,
      "loss": 1.9039,
      "step": 8675
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.8494279980659485,
      "learning_rate": 7.936709396143047e-05,
      "loss": 1.6291,
      "step": 8700
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.4119336009025574,
      "learning_rate": 7.883976279478054e-05,
      "loss": 1.8483,
      "step": 8725
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.7742358446121216,
      "learning_rate": 7.831304691587442e-05,
      "loss": 1.7233,
      "step": 8750
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.395577609539032,
      "learning_rate": 7.77869616403166e-05,
      "loss": 1.8735,
      "step": 8775
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.8739213943481445,
      "learning_rate": 7.726152226537525e-05,
      "loss": 1.7465,
      "step": 8800
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.40818920731544495,
      "learning_rate": 7.673674406953726e-05,
      "loss": 1.944,
      "step": 8825
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.721340537071228,
      "learning_rate": 7.621264231206413e-05,
      "loss": 1.7132,
      "step": 8850
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.443760484457016,
      "learning_rate": 7.568923223254816e-05,
      "loss": 1.8765,
      "step": 8875
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7169843912124634,
      "learning_rate": 7.516652905046932e-05,
      "loss": 1.7358,
      "step": 8900
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.36644789576530457,
      "learning_rate": 7.464454796475274e-05,
      "loss": 1.9276,
      "step": 8925
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.8099789619445801,
      "learning_rate": 7.412330415332687e-05,
      "loss": 1.7667,
      "step": 8950
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.43243011832237244,
      "learning_rate": 7.360281277268188e-05,
      "loss": 1.9876,
      "step": 8975
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.9120553135871887,
      "learning_rate": 7.30830889574292e-05,
      "loss": 1.5996,
      "step": 9000
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4563961327075958,
      "learning_rate": 7.25641478198613e-05,
      "loss": 1.9,
      "step": 9025
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.8255171775817871,
      "learning_rate": 7.204600444951237e-05,
      "loss": 1.6383,
      "step": 9050
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.44991716742515564,
      "learning_rate": 7.152867391271938e-05,
      "loss": 1.9217,
      "step": 9075
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.8340926170349121,
      "learning_rate": 7.101217125218416e-05,
      "loss": 1.7896,
      "step": 9100
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5384005904197693,
      "learning_rate": 7.049651148653593e-05,
      "loss": 1.8354,
      "step": 9125
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.669189989566803,
      "learning_rate": 6.998170960989459e-05,
      "loss": 1.606,
      "step": 9150
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.4633694291114807,
      "learning_rate": 6.946778059143474e-05,
      "loss": 1.7921,
      "step": 9175
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5683429837226868,
      "learning_rate": 6.89547393749504e-05,
      "loss": 1.6647,
      "step": 9200
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.44246867299079895,
      "learning_rate": 6.844260087842049e-05,
      "loss": 1.8279,
      "step": 9225
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.8404858708381653,
      "learning_rate": 6.793137999357504e-05,
      "loss": 1.7003,
      "step": 9250
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.4487658441066742,
      "learning_rate": 6.742109158546223e-05,
      "loss": 1.8691,
      "step": 9275
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7896725535392761,
      "learning_rate": 6.691175049201604e-05,
      "loss": 1.7815,
      "step": 9300
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.43967217206954956,
      "learning_rate": 6.640337152362487e-05,
      "loss": 1.8639,
      "step": 9325
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.9094675183296204,
      "learning_rate": 6.589596946270101e-05,
      "loss": 1.7429,
      "step": 9350
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.47014951705932617,
      "learning_rate": 6.538955906325047e-05,
      "loss": 1.8694,
      "step": 9375
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.9730806350708008,
      "learning_rate": 6.488415505044434e-05,
      "loss": 1.6473,
      "step": 9400
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.44080686569213867,
      "learning_rate": 6.437977212019042e-05,
      "loss": 1.736,
      "step": 9425
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.7497000098228455,
      "learning_rate": 6.387642493870587e-05,
      "loss": 1.7948,
      "step": 9450
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5654792785644531,
      "learning_rate": 6.337412814209097e-05,
      "loss": 1.8641,
      "step": 9475
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.7346946597099304,
      "learning_rate": 6.28728963359032e-05,
      "loss": 1.6141,
      "step": 9500
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.39501118659973145,
      "learning_rate": 6.237274409473286e-05,
      "loss": 1.9431,
      "step": 9525
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7433360815048218,
      "learning_rate": 6.187368596177911e-05,
      "loss": 1.7649,
      "step": 9550
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.49483978748321533,
      "learning_rate": 6.137573644842714e-05,
      "loss": 1.9052,
      "step": 9575
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7299501299858093,
      "learning_rate": 6.08789100338262e-05,
      "loss": 1.6339,
      "step": 9600
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.465958833694458,
      "learning_rate": 6.038322116446855e-05,
      "loss": 1.9759,
      "step": 9625
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7026437520980835,
      "learning_rate": 5.988868425376956e-05,
      "loss": 1.5982,
      "step": 9650
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.45012855529785156,
      "learning_rate": 5.939531368164821e-05,
      "loss": 1.9083,
      "step": 9675
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.932901918888092,
      "learning_rate": 5.8903123794109514e-05,
      "loss": 1.7277,
      "step": 9700
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.46805456280708313,
      "learning_rate": 5.841212890282687e-05,
      "loss": 1.8668,
      "step": 9725
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.8303372263908386,
      "learning_rate": 5.79223432847262e-05,
      "loss": 1.7375,
      "step": 9750
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.4322413504123688,
      "learning_rate": 5.743378118157077e-05,
      "loss": 1.8819,
      "step": 9775
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.9762040376663208,
      "learning_rate": 5.694645679954691e-05,
      "loss": 1.6809,
      "step": 9800
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.44002780318260193,
      "learning_rate": 5.6460384308851186e-05,
      "loss": 1.8578,
      "step": 9825
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.773855447769165,
      "learning_rate": 5.59755778432782e-05,
      "loss": 1.7309,
      "step": 9850
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.4506666660308838,
      "learning_rate": 5.549205149980961e-05,
      "loss": 1.8694,
      "step": 9875
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.911371648311615,
      "learning_rate": 5.500981933820427e-05,
      "loss": 1.6449,
      "step": 9900
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.4834306836128235,
      "learning_rate": 5.452889538058952e-05,
      "loss": 1.8586,
      "step": 9925
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.7960036993026733,
      "learning_rate": 5.404929361105318e-05,
      "loss": 1.7709,
      "step": 9950
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5004296898841858,
      "learning_rate": 5.357102797523713e-05,
      "loss": 1.8612,
      "step": 9975
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.8589841723442078,
      "learning_rate": 5.309411237993187e-05,
      "loss": 1.6711,
      "step": 10000
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.43025878071784973,
      "learning_rate": 5.261856069267186e-05,
      "loss": 1.8704,
      "step": 10025
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7284891605377197,
      "learning_rate": 5.21443867413326e-05,
      "loss": 1.7293,
      "step": 10050
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.4971746504306793,
      "learning_rate": 5.167160431372842e-05,
      "loss": 1.9673,
      "step": 10075
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6860052943229675,
      "learning_rate": 5.120022715721142e-05,
      "loss": 1.546,
      "step": 10100
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6162164807319641,
      "learning_rate": 5.073026897827198e-05,
      "loss": 1.8388,
      "step": 10125
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.8625769019126892,
      "learning_rate": 5.026174344214013e-05,
      "loss": 1.7541,
      "step": 10150
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5378000140190125,
      "learning_rate": 4.9794664172388004e-05,
      "loss": 1.951,
      "step": 10175
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.8191910982131958,
      "learning_rate": 4.932904475053402e-05,
      "loss": 1.6258,
      "step": 10200
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.45255523920059204,
      "learning_rate": 4.8864898715647764e-05,
      "loss": 1.9702,
      "step": 10225
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.7920856475830078,
      "learning_rate": 4.840223956395631e-05,
      "loss": 1.798,
      "step": 10250
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.41578516364097595,
      "learning_rate": 4.794108074845176e-05,
      "loss": 1.9228,
      "step": 10275
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7788666486740112,
      "learning_rate": 4.748143567850031e-05,
      "loss": 1.7646,
      "step": 10300
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5044983625411987,
      "learning_rate": 4.7023317719451944e-05,
      "loss": 1.8463,
      "step": 10325
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.7362743020057678,
      "learning_rate": 4.656674019225216e-05,
      "loss": 1.7333,
      "step": 10350
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5224841237068176,
      "learning_rate": 4.611171637305445e-05,
      "loss": 1.9757,
      "step": 10375
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.8759737610816956,
      "learning_rate": 4.56582594928342e-05,
      "loss": 1.6229,
      "step": 10400
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.39683690667152405,
      "learning_rate": 4.520638273700417e-05,
      "loss": 1.8587,
      "step": 10425
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.8921067714691162,
      "learning_rate": 4.475609924503097e-05,
      "loss": 1.6814,
      "step": 10450
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.4625561237335205,
      "learning_rate": 4.430742211005291e-05,
      "loss": 1.8177,
      "step": 10475
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.705807089805603,
      "learning_rate": 4.386036437849952e-05,
      "loss": 1.6786,
      "step": 10500
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5863417983055115,
      "learning_rate": 4.341493904971191e-05,
      "loss": 1.8082,
      "step": 10525
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.9938459396362305,
      "learning_rate": 4.2971159075565084e-05,
      "loss": 1.6516,
      "step": 10550
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.5372392535209656,
      "learning_rate": 4.252903736009099e-05,
      "loss": 1.879,
      "step": 10575
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6449213624000549,
      "learning_rate": 4.20885867591037e-05,
      "loss": 1.6537,
      "step": 10600
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5168172121047974,
      "learning_rate": 4.164982007982516e-05,
      "loss": 1.8232,
      "step": 10625
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.8591896295547485,
      "learning_rate": 4.121275008051316e-05,
      "loss": 1.6622,
      "step": 10650
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.4565497040748596,
      "learning_rate": 4.077738947009019e-05,
      "loss": 1.9085,
      "step": 10675
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.7627965211868286,
      "learning_rate": 4.03437509077738e-05,
      "loss": 1.6459,
      "step": 10700
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.44367045164108276,
      "learning_rate": 3.992908969579051e-05,
      "loss": 1.9302,
      "step": 10725
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.7200899124145508,
      "learning_rate": 3.9498862877552586e-05,
      "loss": 1.6718,
      "step": 10750
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.5146951675415039,
      "learning_rate": 3.907039528383544e-05,
      "loss": 1.8771,
      "step": 10775
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7771112322807312,
      "learning_rate": 3.86436993734247e-05,
      "loss": 1.6377,
      "step": 10800
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5320529341697693,
      "learning_rate": 3.821878755358984e-05,
      "loss": 1.8328,
      "step": 10825
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.697385847568512,
      "learning_rate": 3.779567217972323e-05,
      "loss": 1.6276,
      "step": 10850
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.44862252473831177,
      "learning_rate": 3.737436555498111e-05,
      "loss": 1.938,
      "step": 10875
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.7893368601799011,
      "learning_rate": 3.695487992992574e-05,
      "loss": 1.683,
      "step": 10900
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.48644253611564636,
      "learning_rate": 3.6537227502169094e-05,
      "loss": 1.9152,
      "step": 10925
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7210928797721863,
      "learning_rate": 3.6121420416018325e-05,
      "loss": 1.7182,
      "step": 10950
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.4637391269207001,
      "learning_rate": 3.570747076212264e-05,
      "loss": 1.8791,
      "step": 10975
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.7959725856781006,
      "learning_rate": 3.5295390577121535e-05,
      "loss": 1.6074,
      "step": 11000
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.49160102009773254,
      "learning_rate": 3.4885191843295084e-05,
      "loss": 1.8997,
      "step": 11025
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.9718382954597473,
      "learning_rate": 3.4476886488215286e-05,
      "loss": 1.6987,
      "step": 11050
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.4868793785572052,
      "learning_rate": 3.407048638439935e-05,
      "loss": 1.9042,
      "step": 11075
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.802683413028717,
      "learning_rate": 3.366600334896448e-05,
      "loss": 1.7909,
      "step": 11100
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.49528050422668457,
      "learning_rate": 3.326344914328429e-05,
      "loss": 1.926,
      "step": 11125
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7046619057655334,
      "learning_rate": 3.2862835472646616e-05,
      "loss": 1.6662,
      "step": 11150
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.4638392925262451,
      "learning_rate": 3.246417398591342e-05,
      "loss": 1.8441,
      "step": 11175
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.7263541221618652,
      "learning_rate": 3.206747627518194e-05,
      "loss": 1.7255,
      "step": 11200
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.4835192859172821,
      "learning_rate": 3.1672753875447566e-05,
      "loss": 1.8707,
      "step": 11225
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8127163648605347,
      "learning_rate": 3.1280018264268575e-05,
      "loss": 1.6006,
      "step": 11250
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.38001856207847595,
      "learning_rate": 3.0889280861432204e-05,
      "loss": 1.7331,
      "step": 11275
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.807091236114502,
      "learning_rate": 3.050055302862279e-05,
      "loss": 1.8016,
      "step": 11300
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.4577963948249817,
      "learning_rate": 3.0113846069091324e-05,
      "loss": 1.7059,
      "step": 11325
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.6633758544921875,
      "learning_rate": 2.972917122732667e-05,
      "loss": 1.736,
      "step": 11350
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.47244271636009216,
      "learning_rate": 2.9346539688728735e-05,
      "loss": 1.7294,
      "step": 11375
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.7035260796546936,
      "learning_rate": 2.89659625792832e-05,
      "loss": 1.6943,
      "step": 11400
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.5224666595458984,
      "learning_rate": 2.858745096523805e-05,
      "loss": 1.6497,
      "step": 11425
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.8533750176429749,
      "learning_rate": 2.8211015852781586e-05,
      "loss": 1.7725,
      "step": 11450
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.4233143925666809,
      "learning_rate": 2.7836668187722704e-05,
      "loss": 1.8186,
      "step": 11475
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7349218130111694,
      "learning_rate": 2.7464418855172314e-05,
      "loss": 1.745,
      "step": 11500
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.45213010907173157,
      "learning_rate": 2.709427867922706e-05,
      "loss": 1.7013,
      "step": 11525
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.7776347398757935,
      "learning_rate": 2.6726258422654493e-05,
      "loss": 1.7429,
      "step": 11550
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.43725189566612244,
      "learning_rate": 2.6360368786580035e-05,
      "loss": 1.6843,
      "step": 11575
    },
    {
      "epoch": 3.09,
      "grad_norm": 1.0114785432815552,
      "learning_rate": 2.5996620410175965e-05,
      "loss": 1.7616,
      "step": 11600
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.46746137738227844,
      "learning_rate": 2.5635023870351992e-05,
      "loss": 1.758,
      "step": 11625
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.5982229709625244,
      "learning_rate": 2.5275589681447665e-05,
      "loss": 1.8105,
      "step": 11650
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.4196501672267914,
      "learning_rate": 2.491832829492664e-05,
      "loss": 1.7194,
      "step": 11675
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.9940605163574219,
      "learning_rate": 2.4563250099072943e-05,
      "loss": 1.6945,
      "step": 11700
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.41221344470977783,
      "learning_rate": 2.4210365418688608e-05,
      "loss": 1.7076,
      "step": 11725
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.8123892545700073,
      "learning_rate": 2.3859684514793768e-05,
      "loss": 1.7348,
      "step": 11750
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.4737672805786133,
      "learning_rate": 2.3511217584328117e-05,
      "loss": 1.669,
      "step": 11775
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.9164390563964844,
      "learning_rate": 2.3164974759854343e-05,
      "loss": 1.7473,
      "step": 11800
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.45597586035728455,
      "learning_rate": 2.2820966109263697e-05,
      "loss": 1.6327,
      "step": 11825
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.7921589612960815,
      "learning_rate": 2.2479201635483127e-05,
      "loss": 1.8159,
      "step": 11850
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.4347776770591736,
      "learning_rate": 2.213969127618436e-05,
      "loss": 1.7452,
      "step": 11875
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.7539151310920715,
      "learning_rate": 2.18024449034951e-05,
      "loss": 1.7747,
      "step": 11900
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.49628838896751404,
      "learning_rate": 2.1467472323711778e-05,
      "loss": 1.6887,
      "step": 11925
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.7760781049728394,
      "learning_rate": 2.1134783277014624e-05,
      "loss": 1.6762,
      "step": 11950
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.44934189319610596,
      "learning_rate": 2.0804387437184226e-05,
      "loss": 1.7366,
      "step": 11975
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.7597469687461853,
      "learning_rate": 2.047629441132044e-05,
      "loss": 1.8127,
      "step": 12000
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.4351312220096588,
      "learning_rate": 2.016350045018639e-05,
      "loss": 1.7396,
      "step": 12025
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.8728140592575073,
      "learning_rate": 1.9839948551323016e-05,
      "loss": 1.8367,
      "step": 12050
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.5182293057441711,
      "learning_rate": 1.9518727509941092e-05,
      "loss": 1.749,
      "step": 12075
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.6714083552360535,
      "learning_rate": 1.91998466663598e-05,
      "loss": 1.7462,
      "step": 12100
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.4980223774909973,
      "learning_rate": 1.88833152928511e-05,
      "loss": 1.7425,
      "step": 12125
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.8282711505889893,
      "learning_rate": 1.856914259337019e-05,
      "loss": 1.7588,
      "step": 12150
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.4844609498977661,
      "learning_rate": 1.8257337703287814e-05,
      "loss": 1.7388,
      "step": 12175
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.881644070148468,
      "learning_rate": 1.7947909689124575e-05,
      "loss": 1.7047,
      "step": 12200
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.41765257716178894,
      "learning_rate": 1.764086754828742e-05,
      "loss": 1.6751,
      "step": 12225
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.8712011575698853,
      "learning_rate": 1.7336220208807896e-05,
      "loss": 1.754,
      "step": 12250
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.4580998420715332,
      "learning_rate": 1.7033976529082675e-05,
      "loss": 1.7368,
      "step": 12275
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.7732531428337097,
      "learning_rate": 1.6734145297615888e-05,
      "loss": 1.7469,
      "step": 12300
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.4827096462249756,
      "learning_rate": 1.6436735232763533e-05,
      "loss": 1.7265,
      "step": 12325
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.594698429107666,
      "learning_rate": 1.6141754982480095e-05,
      "loss": 1.7075,
      "step": 12350
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.5403867363929749,
      "learning_rate": 1.584921312406703e-05,
      "loss": 1.6463,
      "step": 12375
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.9955942034721375,
      "learning_rate": 1.5559118163923268e-05,
      "loss": 1.7739,
      "step": 12400
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.4769687056541443,
      "learning_rate": 1.527147853729798e-05,
      "loss": 1.6927,
      "step": 12425
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.874315619468689,
      "learning_rate": 1.4986302608045321e-05,
      "loss": 1.7682,
      "step": 12450
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.4885202646255493,
      "learning_rate": 1.4703598668381068e-05,
      "loss": 1.7297,
      "step": 12475
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.7714025974273682,
      "learning_rate": 1.442337493864172e-05,
      "loss": 1.7175,
      "step": 12500
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.4298872947692871,
      "learning_rate": 1.4145639567045311e-05,
      "loss": 1.6309,
      "step": 12525
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.8835863471031189,
      "learning_rate": 1.3870400629454495e-05,
      "loss": 1.7385,
      "step": 12550
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.47788119316101074,
      "learning_rate": 1.3597666129141817e-05,
      "loss": 1.7455,
      "step": 12575
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.8048539161682129,
      "learning_rate": 1.3327443996556932e-05,
      "loss": 1.8303,
      "step": 12600
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.46274667978286743,
      "learning_rate": 1.305974208909594e-05,
      "loss": 1.7139,
      "step": 12625
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.844782292842865,
      "learning_rate": 1.2794568190873046e-05,
      "loss": 1.7198,
      "step": 12650
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.4657146632671356,
      "learning_rate": 1.2531930012494175e-05,
      "loss": 1.7478,
      "step": 12675
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.7966165542602539,
      "learning_rate": 1.2271835190832638e-05,
      "loss": 1.7863,
      "step": 12700
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.470430850982666,
      "learning_rate": 1.2014291288807278e-05,
      "loss": 1.7094,
      "step": 12725
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.9254350066184998,
      "learning_rate": 1.1759305795162445e-05,
      "loss": 1.7088,
      "step": 12750
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.48361313343048096,
      "learning_rate": 1.1506886124250204e-05,
      "loss": 1.7804,
      "step": 12775
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.9332243204116821,
      "learning_rate": 1.1257039615814836e-05,
      "loss": 1.7902,
      "step": 12800
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.49739691615104675,
      "learning_rate": 1.1009773534779378e-05,
      "loss": 1.6819,
      "step": 12825
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.9079489707946777,
      "learning_rate": 1.0765095071034347e-05,
      "loss": 1.6342,
      "step": 12850
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.4818003475666046,
      "learning_rate": 1.0523011339228705e-05,
      "loss": 1.6353,
      "step": 12875
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.674405574798584,
      "learning_rate": 1.028352937856304e-05,
      "loss": 1.7434,
      "step": 12900
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.4265480041503906,
      "learning_rate": 1.0046656152584721e-05,
      "loss": 1.8159,
      "step": 12925
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.8319029211997986,
      "learning_rate": 9.812398548985591e-06,
      "loss": 1.806,
      "step": 12950
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.5471558570861816,
      "learning_rate": 9.580763379401648e-06,
      "loss": 1.6993,
      "step": 12975
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.8225387930870056,
      "learning_rate": 9.351757379214799e-06,
      "loss": 1.7591,
      "step": 13000
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.4920126795768738,
      "learning_rate": 9.125387207357306e-06,
      "loss": 1.7241,
      "step": 13025
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.9333743453025818,
      "learning_rate": 8.901659446117982e-06,
      "loss": 1.7531,
      "step": 13050
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.5110807418823242,
      "learning_rate": 8.680580600950782e-06,
      "loss": 1.6964,
      "step": 13075
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.8665085434913635,
      "learning_rate": 8.462157100285729e-06,
      "loss": 1.7184,
      "step": 13100
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.48279181122779846,
      "learning_rate": 8.246395295341946e-06,
      "loss": 1.7758,
      "step": 13125
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.870276927947998,
      "learning_rate": 8.033301459942932e-06,
      "loss": 1.8325,
      "step": 13150
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.48678937554359436,
      "learning_rate": 7.822881790334246e-06,
      "loss": 1.7171,
      "step": 13175
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.6535810232162476,
      "learning_rate": 7.615142405003251e-06,
      "loss": 1.7185,
      "step": 13200
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.6039283871650696,
      "learning_rate": 7.410089344501181e-06,
      "loss": 1.7153,
      "step": 13225
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.7225754261016846,
      "learning_rate": 7.207728571267602e-06,
      "loss": 1.6956,
      "step": 13250
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.507739245891571,
      "learning_rate": 7.008065969456967e-06,
      "loss": 1.7438,
      "step": 13275
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.9008948802947998,
      "learning_rate": 6.811107344767454e-06,
      "loss": 1.7901,
      "step": 13300
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.4954175055027008,
      "learning_rate": 6.616858424272309e-06,
      "loss": 1.6725,
      "step": 13325
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.8450276851654053,
      "learning_rate": 6.425324856253223e-06,
      "loss": 1.6744,
      "step": 13350
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.43696409463882446,
      "learning_rate": 6.23651221003606e-06,
      "loss": 1.7169,
      "step": 13375
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.9457457065582275,
      "learning_rate": 6.050425975828999e-06,
      "loss": 1.8155,
      "step": 13400
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.5125575661659241,
      "learning_rate": 5.867071564562854e-06,
      "loss": 1.6765,
      "step": 13425
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.8015870451927185,
      "learning_rate": 5.686454307733702e-06,
      "loss": 1.6987,
      "step": 13450
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.42194899916648865,
      "learning_rate": 5.508579457247897e-06,
      "loss": 1.7421,
      "step": 13475
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.8567958474159241,
      "learning_rate": 5.333452185269383e-06,
      "loss": 1.7683,
      "step": 13500
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4884057939052582,
      "learning_rate": 5.161077584069229e-06,
      "loss": 1.6782,
      "step": 13525
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.9192647933959961,
      "learning_rate": 4.991460665877623e-06,
      "loss": 1.6065,
      "step": 13550
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.3934783339500427,
      "learning_rate": 4.824606362738093e-06,
      "loss": 1.675,
      "step": 13575
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.697415828704834,
      "learning_rate": 4.660519526364071e-06,
      "loss": 1.749,
      "step": 13600
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.5146145224571228,
      "learning_rate": 4.499204927997902e-06,
      "loss": 1.7424,
      "step": 13625
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.7111435532569885,
      "learning_rate": 4.340667258272058e-06,
      "loss": 1.7531,
      "step": 13650
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.516700804233551,
      "learning_rate": 4.184911127072677e-06,
      "loss": 1.7668,
      "step": 13675
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.988046407699585,
      "learning_rate": 4.031941063405653e-06,
      "loss": 1.7042,
      "step": 13700
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.39935508370399475,
      "learning_rate": 3.881761515264881e-06,
      "loss": 1.6731,
      "step": 13725
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.7055276036262512,
      "learning_rate": 3.7343768495028296e-06,
      "loss": 1.6957,
      "step": 13750
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.387945294380188,
      "learning_rate": 3.589791351703764e-06,
      "loss": 1.6661,
      "step": 13775
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.750531017780304,
      "learning_rate": 3.448009226058935e-06,
      "loss": 1.7644,
      "step": 13800
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.48638156056404114,
      "learning_rate": 3.3090345952444425e-06,
      "loss": 1.7973,
      "step": 13825
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.7128426432609558,
      "learning_rate": 3.1728715003013554e-06,
      "loss": 1.804,
      "step": 13850
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.45985904335975647,
      "learning_rate": 3.0395239005181374e-06,
      "loss": 1.7414,
      "step": 13875
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.8335650563240051,
      "learning_rate": 2.9089956733155845e-06,
      "loss": 1.7055,
      "step": 13900
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.4069942235946655,
      "learning_rate": 2.7812906141340468e-06,
      "loss": 1.7622,
      "step": 13925
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.7826150059700012,
      "learning_rate": 2.6564124363231413e-06,
      "loss": 1.7387,
      "step": 13950
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.5244268774986267,
      "learning_rate": 2.534364771033615e-06,
      "loss": 1.8399,
      "step": 13975
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.7265623211860657,
      "learning_rate": 2.415151167111962e-06,
      "loss": 1.7864,
      "step": 14000
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.5250094532966614,
      "learning_rate": 2.2987750909970408e-06,
      "loss": 1.7121,
      "step": 14025
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.809523344039917,
      "learning_rate": 2.1852399266194314e-06,
      "loss": 1.8144,
      "step": 14050
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.4581606984138489,
      "learning_rate": 2.0745489753029702e-06,
      "loss": 1.729,
      "step": 14075
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.9726049900054932,
      "learning_rate": 1.9667054556687047e-06,
      "loss": 1.7607,
      "step": 14100
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.4214879274368286,
      "learning_rate": 1.8617125035414351e-06,
      "loss": 1.6727,
      "step": 14125
    },
    {
      "epoch": 3.77,
      "grad_norm": 1.0442909002304077,
      "learning_rate": 1.7595731718584197e-06,
      "loss": 1.7095,
      "step": 14150
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.4427865445613861,
      "learning_rate": 1.6602904305806244e-06,
      "loss": 1.6792,
      "step": 14175
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.8060672879219055,
      "learning_rate": 1.5638671666064143e-06,
      "loss": 1.6351,
      "step": 14200
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.509734570980072,
      "learning_rate": 1.4703061836875532e-06,
      "loss": 1.7472,
      "step": 14225
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.8587567806243896,
      "learning_rate": 1.379610202347703e-06,
      "loss": 1.7289,
      "step": 14250
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.4612289071083069,
      "learning_rate": 1.2917818598033316e-06,
      "loss": 1.673,
      "step": 14275
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.851331353187561,
      "learning_rate": 1.206823709886995e-06,
      "loss": 1.75,
      "step": 14300
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.43757230043411255,
      "learning_rate": 1.1247382229730875e-06,
      "loss": 1.6284,
      "step": 14325
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.9740913510322571,
      "learning_rate": 1.045527785906042e-06,
      "loss": 1.695,
      "step": 14350
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.47131770849227905,
      "learning_rate": 9.691947019308756e-07,
      "loss": 1.7607,
      "step": 14375
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.7372340559959412,
      "learning_rate": 8.957411906262426e-07,
      "loss": 1.748,
      "step": 14400
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.4482457935810089,
      "learning_rate": 8.251693878399081e-07,
      "loss": 1.6965,
      "step": 14425
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.7333420515060425,
      "learning_rate": 7.574813456266427e-07,
      "loss": 1.7822,
      "step": 14450
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.5570851564407349,
      "learning_rate": 6.926790321885035e-07,
      "loss": 1.7433,
      "step": 14475
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.9646312594413757,
      "learning_rate": 6.307643318176571e-07,
      "loss": 1.7562,
      "step": 14500
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.4405791461467743,
      "learning_rate": 5.717390448415905e-07,
      "loss": 1.8021,
      "step": 14525
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.7985607981681824,
      "learning_rate": 5.156048875706976e-07,
      "loss": 1.7074,
      "step": 14550
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.5557245016098022,
      "learning_rate": 4.623634922484743e-07,
      "loss": 1.6618,
      "step": 14575
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.7928404808044434,
      "learning_rate": 4.120164070039567e-07,
      "loss": 1.6828,
      "step": 14600
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.496290385723114,
      "learning_rate": 3.645650958067792e-07,
      "loss": 1.7134,
      "step": 14625
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.8719070553779602,
      "learning_rate": 3.200109384245531e-07,
      "loss": 1.7745,
      "step": 14650
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.41529515385627747,
      "learning_rate": 2.7835523038279856e-07,
      "loss": 1.6446,
      "step": 14675
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.9240478873252869,
      "learning_rate": 2.3959918292720816e-07,
      "loss": 1.7605,
      "step": 14700
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.4776739776134491,
      "learning_rate": 2.0374392298850853e-07,
      "loss": 1.8007,
      "step": 14725
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.9331092238426208,
      "learning_rate": 1.7079049314961958e-07,
      "loss": 1.7647,
      "step": 14750
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.5669692158699036,
      "learning_rate": 1.4073985161535685e-07,
      "loss": 1.7478,
      "step": 14775
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.8932188749313354,
      "learning_rate": 1.1359287218459802e-07,
      "loss": 1.699,
      "step": 14800
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.4845229685306549,
      "learning_rate": 8.935034422486998e-08,
      "loss": 1.7059,
      "step": 14825
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.9869847297668457,
      "learning_rate": 6.801297264933393e-08,
      "loss": 1.6988,
      "step": 14850
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.417418897151947,
      "learning_rate": 4.95813778963905e-08,
      "loss": 1.7597,
      "step": 14875
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.7658244371414185,
      "learning_rate": 3.4056095911561e-08,
      "loss": 1.7928,
      "step": 14900
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.5652313232421875,
      "learning_rate": 2.143757813189984e-08,
      "loss": 1.7245,
      "step": 14925
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.7636592984199524,
      "learning_rate": 1.1726191472949399e-08,
      "loss": 1.7189,
      "step": 14950
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.5665173530578613,
      "learning_rate": 4.922218317982008e-09,
      "loss": 1.7453,
      "step": 14975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8908370137214661,
      "learning_rate": 1.025856509828671e-09,
      "loss": 1.8701,
      "step": 15000
    }
  ],
  "logging_steps": 25,
  "max_steps": 15016,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 25,
  "total_flos": 2.5757675810161152e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
